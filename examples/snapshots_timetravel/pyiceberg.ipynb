{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41913d7-1cc8-42d0-8cea-053b4c23d6bb",
   "metadata": {},
   "source": [
    "Read divides parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015f447",
   "metadata": {},
   "source": [
    "\n",
    "5.) Create directories:  mkdir -p data/parquet warehouse  \n",
    "6.) Copy example parquet file from s3:  aws s3 cp s3://ngwpc-hydrofabric/hydrofabric_parquet/2.2/CONUS/divides.parquet data/parquet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6651c9e7-c38d-46d1-b6a4-491baf12cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sqlalchemy\n",
      "  Using cached sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/daniel.cumpton/.local/lib/python3.10/site-packages (from sqlalchemy) (4.11.0)\n",
      "Collecting greenlet>=1\n",
      "  Using cached greenlet-3.2.2-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.2.2 sqlalchemy-2.0.41\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"pyiceberg[pandas]\"\n",
    "!{sys.executable} -m pip install sqlalchemy\n",
    "\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "df = pq.read_table('data/parquet/divides.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d5aaf-d51c-486c-86ac-32eeb2b7e74f",
   "metadata": {},
   "source": [
    "Create data catalog stored in \"warehouse\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96974839-0308-4256-bb3e-0cddfea9d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "warehouse_path = \"warehouse\"\n",
    "catalog = load_catalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        'type': 'sql',\n",
    "        \"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\",\n",
    "        \"warehouse\": f\"file://{warehouse_path}\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe13a4d-0c18-4f2b-953e-a9c658b7225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create Iceberg table for divides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efed8866-134c-40f9-969b-1e4c20b5f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace(\"default\")\n",
    "table = catalog.create_table(\n",
    "    \"default.divides\",\n",
    "    schema=df.schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ed9b6-ba8d-4a54-bbc5-eec900f1cec6",
   "metadata": {},
   "source": [
    "Add divides data to Iceberg table and print the number of rows.  There should be 831777 divides for CONUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9d4717-9055-4ac7-819c-aca6c2435c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.append(df)\n",
    "len(table.scan().to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2b449-667a-4bcd-9c94-d0e604c33f8c",
   "metadata": {},
   "source": [
    "A snapshot was created for the initial append.  Store this snapshot id for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ee6462-5db1-4a40-89b8-3837e63711cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot ID: 91485850664974323; Summary:  operation=Operation.APPEND\n"
     ]
    }
   ],
   "source": [
    "for snapshot in table.snapshots():\n",
    "    print(f\"Snapshot ID: {snapshot.snapshot_id}; Summary:  {snapshot.summary}\")\n",
    "snapshot_id = table.metadata.snapshots[0].snapshot_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f245529-a3c9-4a99-bcb3-fe1078779498",
   "metadata": {},
   "source": [
    "Add a new column for flowpath length in m.  Overwrite original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975224d2-deb0-420f-be80-6b5cac7bbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc\n",
    "df = df.append_column(\"lengthm\", pc.multiply(df[\"lengthkm\"],1000))\n",
    "with table.update_schema() as update_schema:\n",
    "     update_schema.union_by_name(df.schema)\n",
    "table.overwrite(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff7a72-70f6-44e8-a6da-d1c9766c6782",
   "metadata": {},
   "source": [
    "There should be a new \"lengthm\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d826f290-79bf-4bab-a508-cd73bb3aadb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Table.schema of divides(\n",
       "  1: divide_id: optional string,\n",
       "  2: toid: optional string,\n",
       "  3: type: optional string,\n",
       "  4: ds_id: optional double,\n",
       "  5: areasqkm: optional double,\n",
       "  6: vpuid: optional string,\n",
       "  7: id: optional string,\n",
       "  8: lengthkm: optional double,\n",
       "  9: tot_drainage_areasqkm: optional double,\n",
       "  10: has_flowline: optional boolean,\n",
       "  11: geometry: optional binary,\n",
       "  12: lengthm: optional double\n",
       "),\n",
       "partition by: [],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=1597837331107200528, parent_id=1351760718331482642, schema_id=1>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d3f57-e9ef-47e7-a268-05699debcf8f",
   "metadata": {},
   "source": [
    "There should now be three snapshots.  The original, a delete, and an append with the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3a70f2-2271-4bcd-b5fb-83683f36705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot ID: 91485850664974323; Summary:  operation=Operation.APPEND\n",
      "Snapshot ID: 1351760718331482642; Summary:  operation=Operation.DELETE\n",
      "Snapshot ID: 1597837331107200528; Summary:  operation=Operation.APPEND\n"
     ]
    }
   ],
   "source": [
    "for snapshot in table.snapshots():\n",
    "    print(f\"Snapshot ID: {snapshot.snapshot_id}; Summary:  {snapshot.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685eddd-31bb-4c07-a656-6cfb5e97881a",
   "metadata": {},
   "source": [
    "You can use the scan function and the first snapshot ID (this variable was saved earlier) to look at the table before the\n",
    "new column was added.  This table doesn't have lengthm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f47f9e3-7e6b-468b-a978-2c433e662c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "divide_id: large_string\n",
      "toid: large_string\n",
      "type: large_string\n",
      "ds_id: double\n",
      "areasqkm: double\n",
      "vpuid: large_string\n",
      "id: large_string\n",
      "lengthkm: double\n",
      "tot_drainage_areasqkm: double\n",
      "has_flowline: bool\n",
      "geometry: large_binary\n"
     ]
    }
   ],
   "source": [
    "#scan = table.scan(row_filter=\"divide_id\" == \"cat-276\", selected_fields=('divide_id', 'lengthm')).to_arrow()\n",
    "#print(scan)\n",
    "print(table.scan(snapshot_id=snapshot_id).to_arrow().to_string())\n",
    "#table.scan(snapshot_id=snapshot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa874b-b6eb-4d22-b132-6c67450d1c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1527c5-ad53-409a-a296-7cf953ce91f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
