{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### RAS XS Geopackage Viewer\n",
    "\n",
    "An interactive viewer to show the versioned and cataloged HEC-RAS XS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "\n",
    "from icefabric.helpers import load_creds, load_pyiceberg_config, to_geopandas\n",
    "\n",
    "# dir is where the .env file is located\n",
    "load_creds()\n",
    "\n",
    "# Loading the local pyiceberg config settings\n",
    "pyiceberg_config = load_pyiceberg_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "The below code will load a catalog. The SQL catalog is for a local build while the Glue Catalog will pull from S3 tables and requires AWS creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading SQL Catalog\n",
    "# This catalog can be downloaded by running the following commands with AWS creds:\n",
    "# python tools/iceberg/export_catalog.py --namespace conus_reference\n",
    "# python tools/iceberg/export_catalog.py --namespace ras_xs\n",
    "# catalog = load_catalog(\n",
    "#     name=\"sql\",\n",
    "#     type=pyiceberg_config[\"catalog\"][\"sql\"][\"type\"],\n",
    "#     uri=pyiceberg_config[\"catalog\"][\"sql\"][\"uri\"],\n",
    "#     warehouse=pyiceberg_config[\"catalog\"][\"sql\"][\"warehouse\"],\n",
    "# )\n",
    "\n",
    "# Loading Glue Catalog\n",
    "catalog = load_catalog(\"glue\", **{\"type\": \"glue\", \"glue.region\": \"us-east-1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Let's first load our tables that we'll be using and view the data schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.load_table(\"ras_xs.conflated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's load a sample BLE dataset: \"ble_05119_Pulaski\". First we'll scan the pyiceberg catalog for all conflated XS within the BLE area, then pull the reference divides and flowpaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.expressions import EqualTo, In\n",
    "\n",
    "gdf = to_geopandas(\n",
    "    catalog.load_table(\"ras_xs.conflated\")\n",
    "    .scan(row_filter=EqualTo(\"domain\", \"/ble_05119_Pulaski\"))\n",
    "    .to_pandas()\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_divides = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_divides\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "reference_flowpaths = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_flowpaths\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_divides = reference_divides.to_crs(epsg=3857)\n",
    "\n",
    "reference_flowpaths = reference_flowpaths.to_crs(epsg=3857)\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "ref_div_ex = reference_divides.explore(color=\"grey\")\n",
    "ref_flo_ex = reference_flowpaths.explore(m=ref_div_ex, color=\"blue\")\n",
    "gdf.explore(m=ref_flo_ex, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now, we'll see how the representative XS look on this same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rep = to_geopandas(\n",
    "    catalog.load_table(\"ras_xs.representative\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "ref_div_ex = reference_divides.explore(color=\"grey\")\n",
    "ref_flo_ex = reference_flowpaths.explore(m=ref_div_ex, color=\"blue\")\n",
    "gdf_rep.explore(m=ref_flo_ex, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Let's now do the same work, but with a different area: \"mip_18010110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mip = to_geopandas(\n",
    "    catalog.load_table(\"ras_xs.conflated\").scan(row_filter=EqualTo(\"domain\", \"/mip_18010110\")).to_pandas()\n",
    ")\n",
    "gdf_mip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_divides_mip = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_divides\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf_mip[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "reference_flowpaths_mip = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_flowpaths\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf_mip[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "reference_divides_mip = reference_divides_mip.to_crs(epsg=3857)\n",
    "reference_flowpaths_mip = reference_flowpaths_mip.to_crs(epsg=3857)\n",
    "gdf_mip = gdf_mip.to_crs(epsg=3857)\n",
    "\n",
    "ref_div_ex_mip = reference_divides_mip.explore(color=\"grey\")\n",
    "ref_flo_ex_mip = reference_flowpaths_mip.explore(m=ref_div_ex_mip, color=\"blue\")\n",
    "gdf_mip.explore(m=ref_flo_ex_mip, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Let's see how the representative XS look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rep_mip = to_geopandas(\n",
    "    catalog.load_table(\"ras_xs.representative\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf_mip[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "ref_div_ex_mip = reference_divides_mip.explore(color=\"grey\")\n",
    "ref_flo_ex_mip = reference_flowpaths_mip.explore(m=ref_div_ex_mip, color=\"blue\")\n",
    "gdf_rep_mip.explore(m=ref_flo_ex_mip, color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
