{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### RAS XS API Viewer\n",
    "\n",
    "An interactive viewer to show the versioned and cataloged HEC-RAS XS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Make sure to load the prerequisite credentials, then load the iceberg catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyprojroot import here\n",
    "\n",
    "from icefabric.helpers import load_creds, load_pyiceberg_config, to_geopandas\n",
    "\n",
    "os.chdir(here())\n",
    "print(f\"directory changed to {here()}\")\n",
    "load_creds()\n",
    "pyiceberg_config = load_pyiceberg_config()\n",
    "\n",
    "# Loading SQL Catalog\n",
    "# This catalog can be downloaded by running the following commands with AWS creds:\n",
    "# python tools/iceberg/export_catalog.py --namespace conus_reference\n",
    "# python tools/iceberg/export_catalog.py --namespace ras_xs\n",
    "catalog = load_catalog(\n",
    "    name=\"sql\",\n",
    "    type=pyiceberg_config[\"catalog\"][\"sql\"][\"type\"],\n",
    "    uri=pyiceberg_config[\"catalog\"][\"sql\"][\"uri\"],\n",
    "    warehouse=pyiceberg_config[\"catalog\"][\"sql\"][\"warehouse\"],\n",
    ")\n",
    "\n",
    "# Loading Glue Catalog\n",
    "# catalog = load_catalog(\"glue\", **{\"type\": \"glue\", \"glue.region\": \"us-east-1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the API locally\n",
    "def run_api():\n",
    "    \"\"\"Starts the icefabric API locally\"\"\"\n",
    "    !python -m app.main --catalog sql\n",
    "\n",
    "\n",
    "threading.Thread(target=run_api).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Let's call the API to return the conflated cross-sections for a specific flowpath ID to get a sample response. \n",
    "\n",
    "#### NOTE: This API returns a response via a geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import httpx\n",
    "\n",
    "from icefabric.schemas import XsType\n",
    "\n",
    "# Set up parameters for the API call\n",
    "flowpath_id = \"20059822\"\n",
    "url = f\"http://0.0.0.0:8000/v1/ras_xs/{flowpath_id}/\"\n",
    "schema_type = XsType.CONFLATED\n",
    "params = {\n",
    "    \"schema_type\": schema_type.value,\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Use HTTPX to stream the resulting geopackage response\n",
    "with (\n",
    "    httpx.stream(\n",
    "        method=\"GET\",\n",
    "        url=url,\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        timeout=60.0,  # GLUE API requests can be slow depending on the network speed. Adding a 60s timeout to ensure requests go through\n",
    "    ) as response\n",
    "):\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    with open(f\"ras_xs_{flowpath_id}.gpkg\", \"wb\") as file:\n",
    "        for chunk in response.iter_bytes():\n",
    "            file.write(chunk)\n",
    "\n",
    "# Load geopackage into geopandas\n",
    "gdf = gpd.read_file(f\"ras_xs_{flowpath_id}.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Next, pull the reference divides and flowpaths for when we explore the data from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.expressions import In\n",
    "\n",
    "# Pull and filter reference divides/flowpaths from the catalog\n",
    "reference_divides = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_divides\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "reference_flowpaths = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_flowpaths\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "# Convert all data to the EPSG:4326 coordinate reference system\n",
    "reference_divides = reference_divides.to_crs(epsg=4326)\n",
    "reference_flowpaths = reference_flowpaths.to_crs(epsg=4326)\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Finally, project the conflated dataset over the references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_div_ex = reference_divides.explore(color=\"grey\")\n",
    "ref_flo_ex = reference_flowpaths.explore(m=ref_div_ex, color=\"blue\")\n",
    "\n",
    "# View the data\n",
    "gdf.explore(m=ref_flo_ex, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now let's do the same thing, except filter the data so it lies inside a lat/lon bounding box - the following query gets all the data in the state of New Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.routers.ras_xs.router import BoundingBox\n",
    "\n",
    "url = \"http://0.0.0.0:8000/v1/ras_xs/within\"\n",
    "schema_type = XsType.REPRESENTATIVE\n",
    "bbox = BoundingBox(min_lat=31.3323, min_lon=-109.0502, max_lat=37.0002, max_lon=-103.002)\n",
    "params = {\n",
    "    \"schema_type\": schema_type.value,\n",
    "    \"min_lat\": bbox.min_lat,\n",
    "    \"min_lon\": bbox.min_lon,\n",
    "    \"max_lat\": bbox.max_lat,\n",
    "    \"max_lon\": bbox.max_lon,\n",
    "}\n",
    "\n",
    "# Use HTTPX to stream the resulting geopackage response\n",
    "with (\n",
    "    httpx.stream(\n",
    "        method=\"GET\",\n",
    "        url=url,\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        timeout=60.0,  # GLUE API requests can be slow depending on the network speed. Adding a 60s timeout to ensure requests go through\n",
    "    ) as response\n",
    "):\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    with open(\"ras_xs_bbox.gpkg\", \"wb\") as file:\n",
    "        for chunk in response.iter_bytes():\n",
    "            file.write(chunk)\n",
    "\n",
    "# Load geopackage into geopandas\n",
    "gdf_bbox = gpd.read_file(\"ras_xs_bbox.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull and filter reference divides/flowpaths from the catalog\n",
    "reference_divides_bbox = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_divides\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf_bbox[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "reference_flowpaths_bbox = to_geopandas(\n",
    "    catalog.load_table(\"conus_reference.reference_flowpaths\")\n",
    "    .scan(row_filter=In(\"flowpath_id\", gdf_bbox[\"flowpath_id\"]))\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "# Convert all data to the EPSG:4326 coordinate reference system\n",
    "reference_divides_bbox = reference_divides_bbox.to_crs(epsg=4326)\n",
    "reference_flowpaths_bbox = reference_flowpaths_bbox.to_crs(epsg=4326)\n",
    "gdf_bbox = gdf_bbox.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_div_ex_bbox = reference_divides_bbox.explore(color=\"grey\")\n",
    "ref_flo_ex_bbox = reference_flowpaths_bbox.explore(m=ref_div_ex_bbox, color=\"blue\")\n",
    "\n",
    "# View the data\n",
    "gdf_bbox.explore(m=ref_flo_ex_bbox, color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
