{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Icechunk Version Control and Branching\n",
    "Showcase for adding new data over time to an icechunk store, \"time traveling\", and making new branches\n",
    "\n",
    "Requires `.env` with `data` account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from icefabric.helpers import load_creds\n",
    "\n",
    "# dir is where the .env file is located\n",
    "load_creds(dir=Path.cwd().parents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from icefabric.builds import IcechunkRepo, S3Path\n",
    "from icefabric.helpers import virtualize_and_concat_archival_files_on_time\n",
    "from icefabric.schemas import FileType, NGWPCLocations\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "new_repo_s3_path = S3Path(bucket=\"hydrofabric-data\", prefix=\"ic_testing/snodas_yearly_append_test\")\n",
    "new_repo = IcechunkRepo(location=new_repo_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print repo ancestry\n",
    "new_repo.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect first five SNODAS netcdf files from 2009 and combine/virtualize them together into a single dataset\n",
    "snodas_09_vds = virtualize_and_concat_archival_files_on_time(\n",
    "    location=NGWPCLocations.SNODAS_REF.path,\n",
    "    file_date_pattern=\"zz_ssmv11034tS__T0001TTNATS*05HP001.nc\",\n",
    "    file_type=FileType.NETCDF,\n",
    "    manual_file_pattern=\"zz_ssmv11034tS__T0001TTNATS2009*.nc\",\n",
    "    loadable_vars=[\"crs\"],\n",
    "    testing_file_quantity=5,\n",
    ")\n",
    "\n",
    "# Add 09 data to SNODAS repo with a new snapshot\n",
    "new_repo.write_dataset(ds=snodas_09_vds, virtualized=True, commit=\"First commit! 09 data added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a new snapshot, reprint the repo ancestry\n",
    "new_repo.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data now contained within the SNODAS repo\n",
    "snodas_data = new_repo.retrieve_dataset()\n",
    "print(snodas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much like the 09 SNODAS files were collected, do the same for 2010\n",
    "snodas_10_vds = virtualize_and_concat_archival_files_on_time(\n",
    "    location=NGWPCLocations.SNODAS_REF.path,\n",
    "    file_date_pattern=\"zz_ssmv11034tS__T0001TTNATS*05HP001.nc\",\n",
    "    file_type=FileType.NETCDF,\n",
    "    manual_file_pattern=\"zz_ssmv11034tS__T0001TTNATS2010*.nc\",\n",
    "    loadable_vars=[\"crs\"],\n",
    "    testing_file_quantity=5,\n",
    ")\n",
    "\n",
    "# Append 2010 data to SNODAS repo with a new snapshot\n",
    "new_repo.append_virt_data_to_store(\n",
    "    vds=snodas_10_vds, append_dim=\"time\", commit=\"Appended new data from the year 2010\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have another new snapshot with 2010 data, reprint the repo ancestry\n",
    "new_repo.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the new repo collection with both 2009 and 2010 data\n",
    "snodas_data = new_repo.retrieve_dataset()\n",
    "print(snodas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and print the data from the previous snapshot, before 2010 data was added\n",
    "prev_snap_snodas_data = new_repo.retrieve_prev_snapshot()\n",
    "print(prev_snap_snodas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new feature branch based on \"main\" to add 2011 data\n",
    "new_repo.create_new_branch(name=\"2011_feature\")\n",
    "\n",
    "# Much like the 09 SNODAS files were collected, do the same for 2010\n",
    "snodas_11_vds = virtualize_and_concat_archival_files_on_time(\n",
    "    location=NGWPCLocations.SNODAS_REF.path,\n",
    "    file_date_pattern=\"zz_ssmv11034tS__T0001TTNATS*05HP001.nc\",\n",
    "    file_type=FileType.NETCDF,\n",
    "    manual_file_pattern=\"zz_ssmv11034tS__T0001TTNATS2011*.nc\",\n",
    "    loadable_vars=[\"crs\"],\n",
    "    testing_file_quantity=5,\n",
    ")\n",
    "\n",
    "# Append 2011 data to SNODAS repo's new branch with a new snapshot\n",
    "new_repo.append_virt_data_to_store(\n",
    "    vds=snodas_11_vds, append_dim=\"time\", commit=\"Appended new data from the year 2011\", branch=\"2011_feature\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a new branch with new 2011 data, print the history of both branches\n",
    "print(\"NEW BRANCH =====================================\")\n",
    "new_repo.print_history(branch=\"2011_feature\")\n",
    "print(\"MAIN BRANCH ====================================\")\n",
    "new_repo.print_history(branch=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print both branch's datasets - notice the new one has 2011 data\n",
    "snodas_data_feat_branch = new_repo.retrieve_dataset(branch=\"2011_feature\")\n",
    "print(\"NEW BRANCH ========================================================\")\n",
    "print(snodas_data_feat_branch)\n",
    "print(\"===================================================================\")\n",
    "print(\"MAIN BRANCH =======================================================\")\n",
    "print(snodas_data)\n",
    "print(\"===================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup - delete the test repo entirely\n",
    "new_repo.delete_repo(quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icefabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
